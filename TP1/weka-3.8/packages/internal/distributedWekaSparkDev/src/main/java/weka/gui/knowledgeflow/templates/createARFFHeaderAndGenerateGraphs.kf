{
	"flow_name" : "createARFFHeaderAndGenerateGraphs",
	"steps" : [
		{
			"class" : "weka.knowledgeflow.steps.CSVDataSource",
			"properties" : {
				"datasourceOptions" : "-min-slices 4 -output-dir ${user.home}/sparkOutput -master local[*] -cluster-mem -1.0 -overhead 3.0 -mem-fraction 0.6 -charset UTF-8 -comment # -escape \\ -F , -csv-header -Q \"\\'\" -input-file ${WEKA_HOME}/packages/distributedWekaSparkDev/sample_data/hypothyroid_with_header_row.csv -dataset-type trainingData",
				"name" : "CSVDataSource"
			},
			"connections" : {
				"dataFrame" : [
					"ArffHeaderSparkJob"
				]
			},
			"coordinates" : "54,166"
		},
		{
			"class" : "weka.knowledgeflow.steps.ArffHeaderSparkJob",
			"properties" : {
				"jobOptions" : "-header-file-name hypo.arff -data-source weka.distributed.spark.CSVDataSource -debug -cluster-mem -1.0 -overhead 3.0 -mem-fraction 0.6 -charset UTF-8 -comment # -escape \\ -F , -M ? -Q \"\\'\" -dataset-type trainingData -compute-quartiles -compression 50.0 -decimal-places 2",
				"name" : "ArffHeaderSparkJob"
			},
			"connections" : {
				"dataSet" : [
					"TextViewer"
				],
				"image" : [
					"ImageViewer"
				],
				"success" : [
					"AvroDataSink"
				],
				"text" : [
					"TextViewer"
				]
			},
			"coordinates" : "286,166"
		},
		{
			"class" : "weka.knowledgeflow.steps.TextViewer",
			"properties" : {
				"name" : "TextViewer"
			},
			"connections" : {
			},
			"coordinates" : "639,167"
		},
		{
			"class" : "weka.knowledgeflow.steps.ImageViewer",
			"properties" : {
				"name" : "ImageViewer"
			},
			"connections" : {
			},
			"coordinates" : "642,272"
		},
		{
			"class" : "weka.knowledgeflow.steps.AvroDataSink",
			"properties" : {
				"datasinkOptions" : "-min-slices 1 -cluster-mem -1.0 -overhead 3.0 -mem-fraction 0.6 -coalesce -subdir avro",
				"name" : "AvroDataSink"
			},
			"connections" : {
				"dataFrame" : [
					"ParquetDataSink"
				]
			},
			"coordinates" : "287,350"
		},
		{
			"class" : "weka.knowledgeflow.steps.ParquetDataSink",
			"properties" : {
				"datasinkOptions" : "-min-slices 1 -cluster-mem -1.0 -overhead 3.0 -mem-fraction 0.6 -coalesce -subdir parquet",
				"name" : "ParquetDataSink"
			},
			"connections" : {
			},
			"coordinates" : "472,351"
		},
		{
			"class" : "weka.knowledgeflow.steps.Note",
			"properties" : {
				"name" : "Note",
				"noteText" : "Load the hypothyroid csv data\nthat contains a header row."
			},
			"connections" : {
			},
			"coordinates" : "25,263"
		},
		{
			"class" : "weka.knowledgeflow.steps.Note",
			"properties" : {
				"name" : "Note2",
				"noteText" : "Compute ARFF header, summary\nstatistics, quartiles and graphs."
			},
			"connections" : {
			},
			"coordinates" : "348,144"
		},
		{
			"class" : "weka.knowledgeflow.steps.Note",
			"properties" : {
				"name" : "Note3",
				"noteText" : "Save data in Avro format."
			},
			"connections" : {
			},
			"coordinates" : "191,439"
		},
		{
			"class" : "weka.knowledgeflow.steps.Note",
			"properties" : {
				"name" : "Note4",
				"noteText" : "Save data in Parquet format."
			},
			"connections" : {
			},
			"coordinates" : "467,444"
		},
		{
			"class" : "weka.knowledgeflow.steps.Note",
			"properties" : {
				"name" : "Note22",
				"noteText" : "<html><b>NOTE: this flow is configured to run out of the box.</b> It stores output in ${user.home}/sparkOutput.\n\nThis flow demonstrates loading data into the Spark environment via Spark's data frame-based data sources (CSV \nin this case). The (potentially) big datasets are then processed by distributed Weka's strategies for dealing with\nlarge (larger than can fit into desktop RAM) datasets.</html>"
			},
			"connections" : {
			},
			"coordinates" : "36,11"
		}
	]
}
