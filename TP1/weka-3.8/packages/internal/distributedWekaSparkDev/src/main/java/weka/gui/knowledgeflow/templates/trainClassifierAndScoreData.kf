{
	"flow_name" : "trainRFAndScore",
	"steps" : [
		{
			"class" : "weka.knowledgeflow.steps.CSVDataSource",
			"properties" : {
				"datasourceOptions" : "-min-slices 4 -output-dir ${user.home}/sparkOutput -master local[*] -cluster-mem -1.0 -overhead 3.0 -mem-fraction 0.6 -charset UTF-8 -comment # -escape \\ -F , -csv-header -Q \"\\'\" -input-file ${WEKA_HOME}/packages/distributedWekaSparkDev/sample_data/hypothyroid_with_header_row.csv -dataset-type trainingData",
				"name" : "CSVDataSource"
			},
			"connections" : {
				"dataFrame" : [
					"ArffHeaderSparkJob"
				]
			},
			"coordinates" : "28,207"
		},
		{
			"class" : "weka.knowledgeflow.steps.ArffHeaderSparkJob",
			"properties" : {
				"jobOptions" : "-header-file-name hypo.arff -data-source weka.distributed.spark.CSVDataSource -debug -cluster-mem -1.0 -overhead 3.0 -mem-fraction 0.6 -charset UTF-8 -comment # -escape \\ -F , -M ? -Q \"\\'\" -dataset-type trainingData -compression 50.0 -decimal-places 2",
				"name" : "ArffHeaderSparkJob"
			},
			"connections" : {
				"success" : [
					"RandomlyShuffleDataSparkJob"
				]
			},
			"coordinates" : "188,207"
		},
		{
			"class" : "weka.knowledgeflow.steps.Note",
			"properties" : {
				"name" : "Note",
				"noteText" : "<html>Uses the hypothyroid_with_header_row \ncsv file in the <b>sample_data</b> directory of\nthe distributedWekaSpark package as input. \nThe dataset is split into 4 partitions, and \nan ARFF header with additional summary \nmetadata attributes is computed using all the\nCPU cores on your computer.</html>"
			},
			"connections" : {
			},
			"coordinates" : "26,313"
		},
		{
			"class" : "weka.knowledgeflow.steps.RandomizedDataSparkJob",
			"properties" : {
				"jobOptions" : "-class last -seed 1 -num-splits 4 -data-source weka.distributed.spark.CSVDataSource -min-slices 1 -cluster-mem -1.0 -overhead 3.0 -mem-fraction 0.6 -charset UTF-8 -comment # -escape \\ -F , -M ? -Q \"\\'\" -dataset-type trainingData -compression 50.0 -decimal-places 2",
				"name" : "RandomlyShuffleDataSparkJob"
			},
			"connections" : {
				"success" : [
					"WekaClassifierSparkJob"
				]
			},
			"coordinates" : "345,207"
		},
		{
			"class" : "weka.knowledgeflow.steps.WekaClassifierSparkJob",
			"properties" : {
				"jobOptions" : "-model-file-name randomForest.model -num-iterations 1 -class last -data-source weka.distributed.spark.CSVDataSource -min-slices 1 -cluster-mem -1.0 -overhead 3.0 -mem-fraction 0.6 -charset UTF-8 -comment # -escape \\ -F , -M ? -Q \"\\'\" -dataset-type trainingData -compression 50.0 -decimal-places 2 -W weka.classifiers.trees.RandomForest -fold-number -1 -total-folds 1 -seed 1 -- -P 100 -print -I 100 -num-slots 1 -K 0 -M 1.0 -V 0.001 -S 1",
				"name" : "WekaClassifierSparkJob"
			},
			"connections" : {
				"text" : [
					"TextViewer"
				],
				"success" : [
					"WekaScoringSparkJob"
				]
			},
			"coordinates" : "552,207"
		},
		{
			"class" : "weka.knowledgeflow.steps.TextViewer",
			"properties" : {
				"name" : "TextViewer"
			},
			"connections" : {
			},
			"coordinates" : "337,364"
		},
		{
			"class" : "weka.knowledgeflow.steps.WekaScoringSparkJob",
			"properties" : {
				"jobOptions" : "-model-file ${user.home}/sparkOutput/model/randomForest.model -columns-to-output first-last -data-source weka.distributed.spark.CSVDataSource -cluster-mem -1.0 -overhead 3.0 -mem-fraction 0.6 -charset UTF-8 -comment # -escape \\ -F , -M ? -Q \"\\'\" -dataset-type trainingData -compression 50.0 -decimal-places 2",
				"name" : "WekaScoringSparkJob"
			},
			"connections" : {
			},
			"coordinates" : "552,357"
		},
		{
			"class" : "weka.knowledgeflow.steps.Note",
			"properties" : {
				"name" : "Note2",
				"noteText" : "Randomly shuffle and\nstratify the data (RDD) \ninto 4 partitions."
			},
			"connections" : {
			},
			"coordinates" : "320,147"
		},
		{
			"class" : "weka.knowledgeflow.steps.Note",
			"properties" : {
				"name" : "Note3",
				"noteText" : "Train random forests\n(100 trees total - 25 per \npartition)."
			},
			"connections" : {
			},
			"coordinates" : "626,211"
		},
		{
			"class" : "weka.knowledgeflow.steps.Note",
			"properties" : {
				"name" : "Note4",
				"noteText" : "Load the random forest\nclassifier from the output\ndirectory and use it to\nscore all the training data."
			},
			"connections" : {
			},
			"coordinates" : "629,362"
		},
		{
			"class" : "weka.knowledgeflow.steps.Note",
			"properties" : {
				"name" : "Note22",
				"noteText" : "<html><b>NOTE: this flow is configured to run out of the box.</b> It stores output in ${user.home}/sparkOutput.\n\nThis flow demonstrates loading data into the Spark environment via Spark's data frame-based data sources (CSV \nin this case). The (potentially) big datasets are then processed by distributed Weka's strategies for dealing with\nlarge (larger than can fit into desktop RAM) datasets.</html>"
			},
			"connections" : {
			},
			"coordinates" : "16,15"
		}
	]
}
