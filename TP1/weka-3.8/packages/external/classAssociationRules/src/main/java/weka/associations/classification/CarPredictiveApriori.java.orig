/*
 *   This program is free software: you can redistribute it and/or modify
 *   it under the terms of the GNU General Public License as published by
 *   the Free Software Foundation, either version 3 of the License, or
 *   (at your option) any later version.
 *
 *   This program is distributed in the hope that it will be useful,
 *   but WITHOUT ANY WARRANTY; without even the implied warranty of
 *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *   GNU General Public License for more details.
 *
 *   You should have received a copy of the GNU General Public License
 *   along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */

/*
 *    CarPredictiveApriori.java
 *    Copyright (C) 2004 Stefan Mutter
 *
 */

package weka.associations.classification;

import java.io.Reader;
import java.io.FileReader;
import java.io.BufferedReader;
import java.util.Enumeration;
import java.util.Hashtable;
import java.util.TreeSet;
import java.lang.Math;
import weka.core.Instances;
import weka.core.FastVector;
import weka.core.OptionHandler;
import weka.core.Option;
import weka.core.Utils;
import weka.core.UnassignedClassException;
import weka.associations.PredictiveApriori;
import weka.associations.PriorEstimation;
import weka.associations.RuleItem;
import weka.associations.ItemSet;
import weka.associations.RuleGeneration;
    
/**
 * Class implementing the predictive apriori algorithm to mine class association rules. 
 * It searches with an increasing support threshold for the best <i>n<\i> rules 
 * concerning a support-based corrected confidence value. 
 *
 * Reference: T. Scheffer (2001). <i>Finding Association Rules That Trade Support 
 * Optimally against Confidence</i>. Proc of the 5th European Conf.
 * on Principles and Practice of Knowledge Discovery in Databases (PKDD'01),
 * pp. 424-435. Freiburg, Germany: Springer-Verlag. <p>
 *
 * The implementation follows the paper expect for adding a rule to the output of the
 * <i>n<\i> best rules. A rule is added if:
 * the expected predictive accuracy of this rule is among the <i>n<\i> best and it is 
 * not subsumed by a rule with at least the same expected predictive accuracy
 * (out of an unpublished manuscript from T. Scheffer). 
 *
 * Valid option is:<p>
 *   
 * -N required number of rules <br>
 * The required number of rules (default: 100). <p>
 *
 * @author Stefan Mutter (mutter@cs.waikato.ac.nz)
 * @version $Revision$ */


public class CarPredictiveApriori extends PredictiveApriori implements OptionHandler, CARuleMiner {
 
  /** The class index. */  
  protected int m_classIndex;
  

  /**
   * Returns a string describing this associator
   * @return a description of the evaluator suitable for
   * displaying in the explorer/experimenter gui
   */
  public String globalInfo() {
    return "Finds class association rules sorted by predictive accuracy.";
  }

  /**
   * Constructor that allows to sets default values for the 
   * minimum confidence and the maximum number of rules
   * the minimum confidence.
   */
  public CarPredictiveApriori() {

    resetOptions();
  }

  /**
   * Resets the options to the default values.
   */
  public void resetOptions() {
    
    m_numRules = Integer.MAX_VALUE;
    m_premiseCount = 1;
    m_best = new TreeSet();
    m_bestChanged = false;
    m_expectation = 0;
    m_count = 1;
    m_classIndex = -1;
    
   
  }
  
  /**
   * Method that generates all large itemsets with a minimum support, and from
   * these all association rules with a minimum confidence.
   *
   * @param instances the instances to be used for generating the associations
   * @exception Exception if rules can't be built successfully
   */
  public void buildAssociations(Instances instances) throws Exception {
      
    int temp = m_premiseCount, exactNumber = Integer.MAX_VALUE;
    
    if(m_numRules < Integer.MAX_VALUE)
        exactNumber = m_numRules-5;

    if (instances.checkForStringAttributes()) {
      throw new Exception("Can't handle string attributes!");
    }
    m_instances = instances;
    if(m_classIndex == -1)
        m_instances.setClassIndex(m_instances.numAttributes()-1);     
    else
        if(m_classIndex < m_instances.numAttributes() && m_classIndex >= 0)
            m_instances.setClassIndex(m_classIndex);
        else
            throw new Exception("Invalid class index.");
    
    m_priorEstimator = new PriorEstimation(m_instances,m_numRandRules,m_numIntervals,true);
    m_priors = m_priorEstimator.estimatePrior();
    m_midPoints = m_priorEstimator.getMidPoints();
    
    m_Ls = new FastVector();
    m_hashtables = new FastVector();
    for(int i =1; i < m_instances.numAttributes();i++){
      m_bestChanged = false;  
      
      // Find large itemsets and rules
      findLargeItemSets(i);
      findRulesQuickly();
      
      if(m_bestChanged){
        temp =m_premiseCount;
        while(RuleGeneration.expectation(m_premiseCount, m_premiseCount,m_midPoints,m_priors) <= m_expectation){
            m_premiseCount++; 
            if(m_premiseCount > m_instances.numInstances())
                break;
        }
      }
      if(m_premiseCount > m_instances.numInstances()){
        m_allTheRules = new FastVector[3];
        m_allTheRules[0] = new FastVector();
        m_allTheRules[1] = new FastVector();
        m_allTheRules[2] = new FastVector();
      
        int k = 0;
        while(m_best.size()>0 && exactNumber > 0){
            m_allTheRules[0].insertElementAt((ItemSet)((RuleItem)m_best.last()).premise(),k);
            m_allTheRules[1].insertElementAt((ItemSet)((RuleItem)m_best.last()).consequence(),k);
            m_allTheRules[2].insertElementAt(new Double(((RuleItem)m_best.last()).accuracy()),k);
            boolean remove = m_best.remove(m_best.last());
            k++;
            exactNumber--;
        }
        return;    
      }
      if(temp != m_premiseCount && m_Ls.size() > 0){
        FastVector kSets = (FastVector)m_Ls.lastElement();
        m_Ls.removeElementAt(m_Ls.size()-1);
        kSets = ItemSet.deleteItemSets(kSets, m_premiseCount,Integer.MAX_VALUE);
        m_Ls.addElement(kSets);
      }
    }
    // Reserve space for variables
    m_allTheRules = new FastVector[3];
    m_allTheRules[0] = new FastVector();
    m_allTheRules[1] = new FastVector();
    m_allTheRules[2] = new FastVector();
      
    int k = 0;
    while(m_best.size()>0 && exactNumber > 0){
        m_allTheRules[0].insertElementAt((ItemSet)((RuleItem)m_best.last()).premise(),k);
        m_allTheRules[1].insertElementAt((ItemSet)((RuleItem)m_best.last()).consequence(),k);
        m_allTheRules[2].insertElementAt(new Double(((RuleItem)m_best.last()).accuracy()),k);
        boolean remove = m_best.remove(m_best.last());
        k++;
        exactNumber--;
      }
  }



  /**
     * Method that mines the n best class association rules.
     * @return an sorted array of FastVector (depending on the expected predictive accuracy) containing the rules and metric information
     * @param data the instances for which class association rules should be mined
     * @exception Exception if rules can't be built successfully
     */
    public FastVector[] mineCARs(Instances data) throws Exception{
	 
        m_best = new TreeSet();
        m_premiseCount = 1;
        m_bestChanged = false;
        m_expectation = 0;
        m_count = 1;
	buildAssociations(data);
        FastVector[] allCARRules = new FastVector[3];
        allCARRules[0] = new FastVector();
        allCARRules[1] = new FastVector();
        allCARRules[2] = new FastVector();
        for(int k =0; k < m_allTheRules[0].size();k++){
            int[] newPremiseArray = new int[m_instances.numAttributes()-1];
            int help = 0;
            for(int j = 0;j < m_instances.numAttributes();j++){
                if(j != m_instances.classIndex()){
                    newPremiseArray[help] = ((ItemSet)m_allTheRules[0].elementAt(k)).itemAt(j);
                    help++;
                }
            }
            ItemSet newPremise = new ItemSet(m_instances.numInstances(), newPremiseArray);
            newPremise.setCounter (((ItemSet)m_allTheRules[0].elementAt(k)).counter());
            allCARRules[0].addElement(newPremise);
            int[] newConsArray = new int[1];
            newConsArray[0] =((ItemSet)m_allTheRules[1].elementAt(k)).itemAt(m_instances.classIndex());
            ItemSet newCons = new ItemSet(m_instances.numInstances(), newConsArray);
            newCons.setCounter(((ItemSet)m_allTheRules[1].elementAt(k)).counter());
            allCARRules[1].addElement(newCons);
            allCARRules[2].addElement(m_allTheRules[2].elementAt(k));
        }
        
	return allCARRules;
    }

    
   
    /**
     * Gets the instances without the class attribute
     * @return instances without class attribute
     */    
    public Instances getInstancesNoClass() {
      
      Instances noClass = null;
      try{
        noClass = LabeledItemSet.divide(m_instances,false);
      } 
      catch(Exception e){
        e.printStackTrace();
        System.out.println("\n"+e.getMessage());
      }
      //System.out.println(noClass);
      return noClass;
  }  
  
    /**
     * Gets the class attribute of all instances
     * @return Instances containing only the class attribute
     */    
  public Instances getInstancesOnlyClass() {
      
      Instances onlyClass = null;
      try{
        onlyClass = LabeledItemSet.divide(m_instances,true);
      } 
      catch(Exception e){
        e.printStackTrace();
        System.out.println("\n"+e.getMessage());
      }
      return onlyClass;
      
  }  

  /**
   * Returns an enumeration describing the available options.
   *
   * @return an enumeration of all the available options.
   */
  public Enumeration listOptions() {

    String string1 = "\tThe required number of rules. (default: not restricted)",
           string2 = "\tSets the class attribute. (default last) first and last are valid indices.\n\tNote: When used with a classifier, the classifier's class attribute setting overrides this parameter.";
    FastVector newVector = new FastVector(2);

    newVector.addElement(new Option(string1, "N", 1, 
				    "-N <required number of rules output>"));
    
    newVector.addElement(new Option(string2, "c", 1, 
				    "-c <class indes>"));
    
    return newVector.elements();
  }

 
/**
   * Parses a given list of options. Valid option is:<p>
   *   
   * -N required number of rules <br>
   * The required number of rules (default: not restricted). <p>
   * 
   * -c class index <br>
   * Sets the class attribute. (default last)
   * Note: When used with a classifier, the classifier's class attribute setting overrides this parameter. <p>
   *
   * @param options the list of options as an array of strings
   * @exception Exception if an option is not supported 
   */
  public void setOptions(String[] options) throws Exception {
    
    resetOptions();
    String numRulesString = Utils.getOption('N', options),
    classIndexString = Utils.getOption('c', options);
    
    if (numRulesString.length() != 0) 
	m_numRules = Integer.parseInt(numRulesString)+5;
    else
        m_numRules = Integer.MAX_VALUE;
    
    if (classIndexString.length() != 0){
        if(classIndexString.equals("first"))
            m_classIndex = 0;
        else
            if(classIndexString.equals("last"))
                m_classIndex = -1;
            else    
                m_classIndex = Integer.parseInt(classIndexString);
    }
    else
        m_classIndex = -1;
    
  }

  /**
   * Gets the current settings of the PredictiveApriori object.
   *
   * @return an array of strings suitable for passing to setOptions
   */
  public String [] getOptions() {

    String [] options = new String [10];
    int current = 0;
    options[current++] = "-N"; options[current++] = "" + (m_numRules-5);
    if(m_classIndex == -1){
       options[current++] = "-c"; options[current++] = "" + "last";
    }
    else{
        options[current++] = "-c"; options[current++] = "" + m_classIndex;
    }
    while (current < options.length) {
      options[current++] = "";
    }
    return options;
  }
  
  /**
   * Sets the class index
   * @param index the index of the class attribute
   */  
  public void setClassIndex(int index){
      
      m_classIndex = index;
  }
  
  /**
   * Gets the index of the class attribute
   * @return the index of the class attribute
   */  
  public int getClassIndex(){
      
      return m_classIndex;
  }

  /**
   * Returns the tip text for this property
   * @return tip text for this property suitable for
   * displaying in the explorer/experimenter gui
   */
  public String classIndexTipText() {
    return "Index of the class attribute.\n If set to -1, the last attribute will be taken as the class attribute.\nIf used in classification, the class attribute of the classifier overrides this option.";
  }


  /**
   * Outputs the set of mined class association rules
   * @return string containing the n best rules
   */
  public String toString() {

      return super.toString();
  }

 

  /**
   * Method that finds all large itemsets for the given set of instances.
   * @param index the size of the large item sets
   * @exception Exception if an attribute is numeric
   */
  private void findLargeItemSets(int index) throws Exception {
    
    FastVector kMinusOneSets, kSets = new FastVector();
    Hashtable hashtable;
    int i = 0;
    // Find large itemsets
    if(index == 1){
        kSets = CaRuleGeneration.singletons(m_instances);
        ItemSet.upDateCounters(kSets, m_instances);
        kSets = ItemSet.deleteItemSets(kSets, m_premiseCount,Integer.MAX_VALUE);
        if (kSets.size() == 0)
            return;
        m_Ls.addElement(kSets);
    }
    
    if(index >1){
        if(m_Ls.size() > 0)
            kSets = (FastVector)m_Ls.lastElement();
        m_Ls.removeAllElements();
        i = index-2;
        kMinusOneSets = kSets;
        kSets = ItemSet.mergeAllItemSets(kMinusOneSets, i, m_instances.numInstances());
        hashtable = ItemSet.getHashtable(kMinusOneSets, kMinusOneSets.size());
        m_hashtables.addElement(hashtable);
        kSets = ItemSet.pruneItemSets(kSets, hashtable);
        ItemSet.upDateCounters(kSets, m_instances);
        kSets = ItemSet.deleteItemSets(kSets, m_premiseCount,Integer.MAX_VALUE);
        if(kSets.size() == 0)
          return;
        m_Ls.addElement(kSets);
    }
  } 


  

  /** 
   * Method that finds all association rules.
   *
   * @exception Exception if an attribute is numeric
   */
  private void findRulesQuickly() throws Exception {

    FastVector[] rules;
    
    CaRuleGeneration currentLItemSet;
    // Build rules
    for (int j = 0; j < m_Ls.size(); j++) {
      FastVector currentItemSets = (FastVector)m_Ls.elementAt(j);
      Enumeration enumItemSets = currentItemSets.elements();
      while (enumItemSets.hasMoreElements()) {
        currentLItemSet = new CaRuleGeneration((ItemSet)enumItemSets.nextElement());
        m_best = currentLItemSet.generateRules(m_numRules, m_midPoints,m_priors,m_expectation,
                                        m_instances,m_best,m_count);
        m_count = currentLItemSet.count();
        if(!m_bestChanged && currentLItemSet.change())
                m_bestChanged = true;
        if(m_best.size() >0)
            m_expectation = ((RuleItem)m_best.first()).accuracy();
        else 
            m_expectation =0;
      }
    }
  }

  /**
   * Returns the metric string for the chosen metric type.
   * Predictive apriori uses the estimated predictive accuracy.
   * Therefore the metric string is "acc".
   * @return string "acc"
   */
  public String metricString() {
      
      return "acc";
  }
 
   


  /**
   * Main method for testing this class.
   * @param options Options for the algorithms
   */
  public static void main(String[] options) {

    String trainFileString;
    StringBuffer text = new StringBuffer();
    CarPredictiveApriori apriori = new CarPredictiveApriori();
    Reader reader;

    try {
      text.append("\n\nCarPredictiveApriori options:\n\n");
      text.append("-t <training file>\n");
      text.append("\tThe name of the training file.\n");
      Enumeration enum = apriori.listOptions();
      while (enum.hasMoreElements()) {
	Option option = (Option)enum.nextElement();
	text.append(option.synopsis()+'\n');
	text.append(option.description()+'\n');
      }
      trainFileString = Utils.getOption('t', options);
      if (trainFileString.length() == 0) 
	throw new Exception("No training file given!");
      apriori.setOptions(options);
      reader = new BufferedReader(new FileReader(trainFileString));
      apriori.mineCARs(new Instances(reader));
      System.out.println(apriori);
    } catch(Exception e) {
      e.printStackTrace();
      System.out.println("\n"+e.getMessage()+text);
    }
  }
  
}



